{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "\n",
    "open('cafe.txt', 'w', encoding='utf_8').write('café')\n",
    "\n",
    "print(open('cafe.txt').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "\n",
    "import sys, locale\n",
    "\n",
    "expressions = \"\"\"\n",
    "    locale.getpreferredencoding()\n",
    "    type(my_file)\n",
    "    my_file.encoding\n",
    "    sys.stdout.isatty()\n",
    "    sys.stdout.encoding\n",
    "    sys.stdin.isatty()\n",
    "    sys.stdin.encoding\n",
    "    sys.stderr.isatty()\n",
    "    sys.stderr.encoding\n",
    "    sys.getdefaultencoding()\n",
    "    sys.getfilesystemencoding()\n",
    "\"\"\"\n",
    "\n",
    "my_file = open('dummy', 'w')\n",
    "\n",
    "for expression in expressions.split():\n",
    "    value = eval(expression)\n",
    "    print(expression.rjust(30), '->', repr(value))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "\n",
    "from unicodedata import normalize\n",
    "len(normalize('NFC',s1)), len(normalize('NFC',s2))\n",
    "len(normalize('NFD',s1)), len(normalize('NFD',s2))\n",
    "\n",
    "normalize('NFC',s1), normalize('NFC',s2)\n",
    "normalize('NFD',s1), normalize('NFD',s2)\n",
    "\n",
    "normalize('NFC',s1) == normalize('NFC',s2)\n",
    "normalize('NFD',s1) == normalize('NFD',s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ω Ω False\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "\n",
    "from unicodedata import normalize, name\n",
    "ohm = '\\u2126'\n",
    "name(ohm)\n",
    "\n",
    "ohm_c = normalize('NFC', ohm)\n",
    "name(ohm_c)\n",
    "\n",
    "print(ohm, ohm_c, ohm == ohm_c)\n",
    "\n",
    "normalize('NFC', ohm) == normalize('NFC', ohm_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ß ss ß\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "\n",
    "eszett = 'ß'\n",
    "name(eszett)\n",
    "\n",
    "eszett_cf = eszett.casefold()\n",
    "eszett_cf2 = eszett.lower()\n",
    "\n",
    "print(eszett, eszett_cf, eszett_cf2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "\n",
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "s1 == s2\n",
    "\n",
    "from unicodedata import normalize\n",
    "\n",
    "def nfc_equal(str1, str2):\n",
    "    return normalize('NFC', str1) == normalize('NFC', str2)\n",
    "\n",
    "def fold_equal(str1, str2):\n",
    "    return (normalize('NFC', str1).casefold() == normalize('NFC', str2).casefold())\n",
    "\n",
    "print(nfc_equal(s1, s2))\n",
    "\n",
    "print(nfc_equal('A', 'a'))\n",
    "\n",
    "s3 = 'Straße'\n",
    "s4 = 'strasse'\n",
    "\n",
    "print(s3 == s4)\n",
    "\n",
    "print(nfc_equal(s3, s4))\n",
    "\n",
    "print(fold_equal(s3, s4))\n",
    "\n",
    "print(fold_equal(s1, s2))\n",
    "\n",
    "print(fold_equal('A', 'a'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“Herr Voß: • ½ cup of Œtker™ caffe latte • bowl of acai.”\n",
      "Ζεφυρος, Zefiro\n",
      "Straße\n",
      "cafe\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "def shave_marks(txt):\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)\n",
    "    shaved = ''.join(c for c in norm_txt if not unicodedata.combining(c))\n",
    "    return unicodedata.normalize('NFC', shaved)\n",
    "\n",
    "order = '“Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”'\n",
    "print(shave_marks(order))\n",
    "\n",
    "Greek = 'Ζέφυρος, Zéfiro' \n",
    "print(shave_marks(Greek))\n",
    "\n",
    "print(shave_marks('Straße'))\n",
    "\n",
    "print(shave_marks('café'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "\n",
    "def shave_marks_latin(txt):\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)\n",
    "    latin_base = False\n",
    "    keepers = []\n",
    "    for c in norm_txt:\n",
    "        if unicodedata.combining(c) and latin_base:\n",
    "            continue\n",
    "        keepers.append(c)\n",
    "        if not unicodedata.combining(c):\n",
    "            latin_base = c in string.ascii_letters\n",
    "    shaved = ''.join(keepers)\n",
    "    return unicodedata.normalize('NFC', shaved)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Herr Voß: - ½ cup of OEtker(TM) caffè latte - bowl of açaí.\"\n",
      "\"Herr Voss: - ½ cup of OEtker(TM) caffe latte - bowl of acai.\"\n"
     ]
    }
   ],
   "source": [
    "#9\n",
    "\n",
    "single_map = str.maketrans(\"\"\"‚ƒ„†ˆ‹‘’“”•–—˜›\"\"\", \"\"\"'f\"*^<''\"\"---~>\"\"\")\n",
    "\n",
    "multi_map = str.maketrans({\n",
    "    '€': '<euro>',\n",
    "    '…': '...',\n",
    "    'Œ': 'OE',\n",
    "    '™': '(TM)',\n",
    "    'œ': 'oe',\n",
    "    '‰': '<per mille>',\n",
    "    '‡': '**',\n",
    "})\n",
    "\n",
    "multi_map.update(single_map)\n",
    "\n",
    "def dewinize(txt):\n",
    "    return txt.translate(multi_map)\n",
    "\n",
    "def asciize(txt):\n",
    "    no_marks = shave_marks(dewinize(txt))\n",
    "    no_marks = no_marks.replace('ß', 'ss')\n",
    "    return no_marks.translate(single_map)\n",
    "\n",
    "order = '“Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”'\n",
    "\n",
    "print(dewinize(order))\n",
    "\n",
    "print(asciize(order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "\n",
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "sorted_fruits = sorted(fruits)\n",
    "print(sorted_fruits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "\n",
    "import pyuca\n",
    "\n",
    "coll = pyuca.Collator()\n",
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "sorted_fruits = sorted(fruits, key=coll.sort_key)\n",
    "print(sorted_fruits)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U+0031\t  1   \tre_dig\tisdig\tisnum\t 1.00\tDIGIT ONE\n",
      "U+00bc\t  ¼   \t-\t-\tisnum\t 0.25\tVULGAR FRACTION ONE QUARTER\n",
      "U+00b2\t  ²   \t-\tisdig\tisnum\t 2.00\tSUPERSCRIPT TWO\n",
      "U+0969\t  ३   \tre_dig\tisdig\tisnum\t 3.00\tDEVANAGARI DIGIT THREE\n",
      "U+136b\t  ፫   \t-\tisdig\tisnum\t 3.00\tETHIOPIC DIGIT THREE\n",
      "U+216b\t  Ⅻ   \t-\t-\tisnum\t12.00\tROMAN NUMERAL TWELVE\n",
      "U+2466\t  ⑦   \t-\tisdig\tisnum\t 7.00\tCIRCLED DIGIT SEVEN\n",
      "U+2480\t  ⒀   \t-\t-\tisnum\t13.00\tPARENTHESIZED NUMBER THIRTEEN\n",
      "U+3285\t  ㊅   \t-\t-\tisnum\t 6.00\tCIRCLED IDEOGRAPH SIX\n"
     ]
    }
   ],
   "source": [
    "#12\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "re_digit = re.compile(r'\\d')\n",
    "sample = '1\\xbc\\xb2\\u0969\\u136b\\u216b\\u2466\\u2480\\u3285'\n",
    "\n",
    "for char in sample:\n",
    "    print('U+%04x' % ord(char), \n",
    "          char.center(6), \n",
    "          're_dig' if re_digit.match(char) else '-', \n",
    "          'isdig' if char.isdigit() else '-', \n",
    "          'isnum' if char.isnumeric() else '-', \n",
    "          format(unicodedata.numeric(char), '5.2f'), \n",
    "          unicodedata.name(char), \n",
    "          sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13\n",
    "\n",
    "import re\n",
    "\n",
    "re_numbers_str = re.compile(r'\\d+')\n",
    "re_words_str = re.compile(r'\\w+')\n",
    "re_numbers_bytes = re.compile(rb'\\d+')\n",
    "re_words_bytes = re.compile(rb'\\w+')\n",
    "\n",
    "text_str = (\"Ramanujan saw \\u0be7\\u0bed\\u0be8\\u0bef\"\n",
    "            \" as 1729 = 1³ + 12³ = 9³ + 10³.\")\n",
    "\n",
    "text_bytes = text_str.encode('utf_8')\n",
    "\n",
    "print('Text', repr(text_str), sep='\\n ')\n",
    "print('Numbers')\n",
    "print(' str  :', re_numbers_str.findall(text_str))\n",
    "print(' bytes:', re_numbers_bytes.findall(text_bytes))\n",
    "print('Words')\n",
    "print(' str  :', re_words_str.findall(text_str))\n",
    "print(' bytes:', re_words_bytes.findall(text_bytes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14\n",
    "\n",
    "import os\n",
    "\n",
    "os.listdir('.')\n",
    "\n",
    "os.listdir(b'.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15\n",
    "\n",
    "os.listdir('..')\n",
    "\n",
    "os.listdir(b'..')\n",
    "\n",
    "pi_name_bytes = os.listdir(b'.')[1]\n",
    "pi_name_str = pi_name_bytes.decode('ascii', 'surrogateescape')\n",
    "\n",
    "print(pi_name_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
